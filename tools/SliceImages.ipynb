{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage import measure\n",
    "import glob\n",
    "import os\n",
    "from math import floor\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import json\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import floor, ceil\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import smtplib, ssl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in image and find dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    # Number of tiles to slice the image into. Must be a square rootable number. \n",
    "    NUM_SLICES = 9\n",
    "    \n",
    "    # When we stride the image, how much overlap do we want? Put as percentage\n",
    "    TILE_OVERLAP = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slicer():\n",
    "    def __init__(self, image_dir, img_output_dir, annotation_file, config, output_file = None):\n",
    "        assert os.path.isdir(os.getcwd() + \"/\" + image_dir), \"Image directory does not exist at path: {}\".format(image_dir)\n",
    "        assert os.path.isfile(os.getcwd() + \"/\" + annotation_file), \"Annotation file does not exist at path: {}\".format(annotation_file)\n",
    "        assert config.NUM_SLICES == int(sqrt(config.NUM_SLICES + 0.5))**2 or config.NUM_SLICES == 1, \"NUM_SLICES must be an evenly square rootable number or 1\"\n",
    "        if not os.path.isdir(os.getcwd() + \"/\" + img_output_dir):\n",
    "            print(\"Made image output directory at {}\".format(img_output_dir))\n",
    "            os.mkdir(os.getcwd() + \"/\" + img_output_dir)\n",
    "        \n",
    "        self.image_dir = image_dir\n",
    "        self.img_output_dir = img_output_dir\n",
    "        self.config = config\n",
    "        self.output_file = output_file\n",
    "        self.coco_annotation = COCO(annotation_file)\n",
    "        self.sliced_annotations = {\n",
    "            \"images\": [], \n",
    "            \"annotations\": [], \n",
    "            \"categories\": [\n",
    "                {\n",
    "                    'id': 1, \n",
    "                    'name': 'Structure', \n",
    "                    'supercategory': 'Structure'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def slice_dataset(self, save_masks = False):\n",
    "        # Get image IDs for all images in dataset\n",
    "        imgIds = self.coco_annotation.getImgIds()\n",
    "        images = self.coco_annotation.loadImgs(ids = imgIds)\n",
    "        \n",
    "        image_num = 0\n",
    "        image_id = 0\n",
    "        annotation_id = 0\n",
    "        \n",
    "        for x in tnrange(len(imgIds), desc='Processing images...'):\n",
    "\n",
    "            # Try to open image. Otherwise, continue\n",
    "            try:\n",
    "                im = Image.open(self.image_dir + \"/{}\".format(images[x][\"file_name\"]))\n",
    "            except:\n",
    "                continue\n",
    "            print(\"Processing image: {}\".format(images[x][\"file_name\"]))\n",
    "            \n",
    "            # Get rows and cols\n",
    "            rows = im.size[0]\n",
    "            cols = im.size[1]\n",
    "            \n",
    "            # Get num rows and cols for each slice\n",
    "            slice_rows = floor(rows / self.config.NUM_SLICES)\n",
    "            slice_cols = floor(cols / self.config.NUM_SLICES)\n",
    "            \n",
    "            # Calculate the x and y stride values\n",
    "            x_stride = floor(slice_cols * (1 - self.config.TILE_OVERLAP))\n",
    "            y_stride = floor(slice_rows * (1 - self.config.TILE_OVERLAP))\n",
    "            \n",
    "            # Get annotation IDs pertaining to image\n",
    "            annIds = self.coco_annotation.getAnnIds(imgIds = imgIds[x])\n",
    "\n",
    "            # Get all annotations pertaining to image\n",
    "            annotations = self.coco_annotation.loadAnns(ids = annIds)\n",
    "\n",
    "            # Get original mask of image\n",
    "            original_mask = self.coco_annotation.annToMask(annotations[0])\n",
    "            \n",
    "            for j in tnrange(len(annotations), desc='Creating mask...'):\n",
    "                original_mask += self.coco_annotation.annToMask(annotations[j])\n",
    "            \n",
    "            # Perform operations on each crop. Traverse image\n",
    "            for i in range(slice_rows, rows, y_stride):\n",
    "                for j in range(slice_cols, cols, x_stride):\n",
    "                    \n",
    "                    # Crop image\n",
    "                    im_crop = im.crop((j - slice_cols, i - slice_rows, j, i))\n",
    "                    \n",
    "                    # Crop mask and pad with zeros\n",
    "                    mask_crop = original_mask[i - slice_rows : i, j - slice_cols : j]\n",
    "                    mask_crop_pad = np.zeros((mask_crop.shape[0] + 2, mask_crop.shape[1] + 2))\n",
    "                    mask_crop_pad[1:mask_crop.shape[0] + 1, 1:mask_crop.shape[1] + 1] = mask_crop\n",
    "                    mask_crop = mask_crop_pad\n",
    "                    \n",
    "                    # Check if sizes between cropped image and cropped mask are different. Also check\n",
    "                    # if the cropped mask is empty. If so, skip\n",
    "                    if im_crop.size[0] != mask_crop.shape[1] - 2 or im_crop.size[1] != mask_crop.shape[0] - 2:\n",
    "                        continue\n",
    "                    if np.sum(mask_crop) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Try to save image in output dir. Otherwise, continue\n",
    "                    try:\n",
    "                        im_crop.save(self.img_output_dir + \"/{}.jpg\".format(image_num))\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                    \n",
    "                    if save_masks:\n",
    "                        # Prepare mask to save as image\n",
    "                        binary_mask_to_int = mask_crop.astype(np.uint8)\n",
    "                        binary_mask_to_int[binary_mask_to_int > 0] = 255\n",
    "                        binary_mask_to_int = Image.fromarray(binary_mask_to_int)\n",
    "                        binary_mask_to_int.save(self.img_output_dir + \"/{}-mask.jpg\".format(image_num))\n",
    "                    \n",
    "                    # Add image annotation to COCO JSON collection\n",
    "                    self.sliced_annotations[\"images\"].append({\n",
    "                        'id': image_id, \n",
    "                        'file_name': \"{}.jpg\".format(image_num), \n",
    "                        'width': im_crop.size[0], \n",
    "                        'height': im_crop.size[1]\n",
    "                    })\n",
    "                    \n",
    "                    # Increment image_num\n",
    "                    image_num = image_num + 1\n",
    "                    \n",
    "                    contours = measure.find_contours(mask_crop, 0.5)\n",
    "                    segmentations = list()\n",
    "\n",
    "                    # Add segmentations to each annotation\n",
    "                    for contour in contours:\n",
    "                        contour = np.flip(contour, axis=1)\n",
    "                        segmentation = contour.ravel().tolist()\n",
    "                        segmentations.append(segmentation)\n",
    "                    \n",
    "                    for segmentation in segmentations:\n",
    "                        \n",
    "                        # Group segmentations into pairs\n",
    "                        segmentations_grouped = [[segmentation[i], segmentation[i + 1]] for i in range(0, len(segmentation) - 2, 2)]\n",
    "                        \n",
    "                        # Determine the boundaries of the bounding box\n",
    "                        top = np.inf\n",
    "                        bottom = 0\n",
    "                        left = np.inf\n",
    "                        right = 0\n",
    "                        \n",
    "                        for index in segmentations_grouped:\n",
    "                            if index[0] < top:\n",
    "                                top = index[0]\n",
    "                            if index[0] > bottom:\n",
    "                                bottom = index[0]\n",
    "                            if index[1] < left:\n",
    "                                left = index[1]\n",
    "                            if index[1] > right:                      \n",
    "                                right = index[1] \n",
    "                        \n",
    "                        # Get largest connected component to find area\n",
    "                        bbox_crop = mask_crop[floor(left) : ceil(right), floor(top) : ceil(bottom)]\n",
    "                        \n",
    "                        # Construct 3x3 filter of ones\n",
    "                        structure = np.ones((3, 3), dtype = np.int)\n",
    "                        \n",
    "                        # Separate out connected components\n",
    "                        labeled, ncomponents = label(bbox_crop, structure)\n",
    "                        \n",
    "                        # Find the area of the largest connected component\n",
    "                        max_len = 0\n",
    "\n",
    "                        for num in range(1, ncomponents + 1, 1):\n",
    "                            this_len = 0\n",
    "                            for row in range(np.shape(labeled)[0]):\n",
    "                                for col in range(np.shape(labeled)[1]):\n",
    "                                    if labeled[row, col] == num:\n",
    "                                        this_len = this_len + 1\n",
    "\n",
    "                            if this_len > max_len:\n",
    "                                max_len = this_len\n",
    "                        \n",
    "                        # 166 was the first area where building \n",
    "                        # was not sticking out from side\n",
    "                        if max_len == 166:\n",
    "                            continue\n",
    "\n",
    "                        self.sliced_annotations[\"annotations\"].append({\n",
    "                            'id': annotation_id, \n",
    "                            'image_id': image_id,\n",
    "                            'segmentation': [[int(segmentation[i]) for i in range(len(segmentation))]], \n",
    "                            'area': int(max_len), \n",
    "                            'bbox': [int(top), int(left), int(bottom - top), int(right - left)], \n",
    "                            'iscrowd': 0, \n",
    "                            'category_id': 1\n",
    "                        })\n",
    "                        \n",
    "                        annotation_id = annotation_id + 1\n",
    "\n",
    "                    image_id = image_id + 1\n",
    "                    \n",
    "        # Save the annotations file\n",
    "        with open(self.output_file, \"w\") as outfile:\n",
    "            json.dump(self.sliced_annotations, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer = Slicer(image_dir = \"datasets/Downtown/test/images\", \n",
    "                img_output_dir = \"datasets/Downtown_Sliced/test/images\", \n",
    "                annotation_file = \"datasets/Downtown/test/annotations.json\", \n",
    "                config = Config(), \n",
    "                output_file = \"datasets/Downtown_Sliced/test/annotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer.slice_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
